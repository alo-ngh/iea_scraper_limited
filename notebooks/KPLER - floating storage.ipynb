{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KPLER API - floating Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "from numpy import int64\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floating storage data by continent & vessel type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"Authorization\": \"Basic ZGlvbnlzaWEubHluZ29wb3Vsb3VAaWVhLm9yZzpHbHJ6dDB6bg==\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Get vessels data from '/v1/fleet-metrics/vessels'\n",
    "\n",
    "Through this endpoint is provided the list of vessels with their cargo per day on a given period (of 31 days) and their location, for the Floating Storage.\n",
    "\n",
    "parameters: \n",
    "- \"metric\": \"floating_storage\",\n",
    "- \"zones\":\"world\",\n",
    "- \"floatingStorageDurationMin\":\"12\", \n",
    "- \"floatingStorageDurationMax\":\"Inf\", \n",
    "- \"period\": \"daily\", \n",
    "- \"products\":\"crude/co\", \n",
    "- \"unit\":\"kb\"\n",
    "\n",
    "\n",
    "Each query can retreive data of 31 days only. So to get the full timeseries starting from 2016  we need to loop through the time range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Timestamp('2016-01-31 00:00:00', freq='M'),\n",
       " Timestamp('2016-02-29 00:00:00', freq='M'),\n",
       " Timestamp('2016-03-31 00:00:00', freq='M'),\n",
       " Timestamp('2016-04-30 00:00:00', freq='M'),\n",
       " Timestamp('2016-05-31 00:00:00', freq='M'),\n",
       " Timestamp('2016-06-30 00:00:00', freq='M'),\n",
       " Timestamp('2016-07-31 00:00:00', freq='M'),\n",
       " Timestamp('2016-08-31 00:00:00', freq='M'),\n",
       " Timestamp('2016-09-30 00:00:00', freq='M'),\n",
       " Timestamp('2016-10-31 00:00:00', freq='M'),\n",
       " Timestamp('2016-11-30 00:00:00', freq='M'),\n",
       " Timestamp('2016-12-31 00:00:00', freq='M'),\n",
       " Timestamp('2017-01-31 00:00:00', freq='M'),\n",
       " Timestamp('2017-02-28 00:00:00', freq='M'),\n",
       " Timestamp('2017-03-31 00:00:00', freq='M'),\n",
       " Timestamp('2017-04-30 00:00:00', freq='M'),\n",
       " Timestamp('2017-05-31 00:00:00', freq='M'),\n",
       " Timestamp('2017-06-30 00:00:00', freq='M'),\n",
       " Timestamp('2017-07-31 00:00:00', freq='M'),\n",
       " Timestamp('2017-08-31 00:00:00', freq='M'),\n",
       " Timestamp('2017-09-30 00:00:00', freq='M'),\n",
       " Timestamp('2017-10-31 00:00:00', freq='M'),\n",
       " Timestamp('2017-11-30 00:00:00', freq='M'),\n",
       " Timestamp('2017-12-31 00:00:00', freq='M'),\n",
       " Timestamp('2018-01-31 00:00:00', freq='M'),\n",
       " Timestamp('2018-02-28 00:00:00', freq='M'),\n",
       " Timestamp('2018-03-31 00:00:00', freq='M'),\n",
       " Timestamp('2018-04-30 00:00:00', freq='M'),\n",
       " Timestamp('2018-05-31 00:00:00', freq='M'),\n",
       " Timestamp('2018-06-30 00:00:00', freq='M'),\n",
       " Timestamp('2018-07-31 00:00:00', freq='M'),\n",
       " Timestamp('2018-08-31 00:00:00', freq='M'),\n",
       " Timestamp('2018-09-30 00:00:00', freq='M'),\n",
       " Timestamp('2018-10-31 00:00:00', freq='M'),\n",
       " Timestamp('2018-11-30 00:00:00', freq='M'),\n",
       " Timestamp('2018-12-31 00:00:00', freq='M'),\n",
       " Timestamp('2019-01-31 00:00:00', freq='M'),\n",
       " Timestamp('2019-02-28 00:00:00', freq='M'),\n",
       " Timestamp('2019-03-31 00:00:00', freq='M'),\n",
       " Timestamp('2019-04-30 00:00:00', freq='M'),\n",
       " Timestamp('2019-05-31 00:00:00', freq='M'),\n",
       " Timestamp('2019-06-30 00:00:00', freq='M'),\n",
       " Timestamp('2019-07-31 00:00:00', freq='M'),\n",
       " Timestamp('2019-08-31 00:00:00', freq='M'),\n",
       " Timestamp('2019-09-30 00:00:00', freq='M'),\n",
       " Timestamp('2019-10-31 00:00:00', freq='M'),\n",
       " Timestamp('2019-11-30 00:00:00', freq='M'),\n",
       " Timestamp('2019-12-31 00:00:00', freq='M'),\n",
       " Timestamp('2020-01-31 00:00:00', freq='M'),\n",
       " Timestamp('2020-02-29 00:00:00', freq='M'),\n",
       " Timestamp('2020-03-31 00:00:00', freq='M'),\n",
       " Timestamp('2020-04-30 00:00:00', freq='M'),\n",
       " Timestamp('2020-05-31 00:00:00', freq='M'),\n",
       " Timestamp('2020-06-30 00:00:00', freq='M'),\n",
       " Timestamp('2020-07-31 00:00:00', freq='M'),\n",
       " Timestamp('2020-08-31 00:00:00', freq='M'),\n",
       " Timestamp('2020-09-30 00:00:00', freq='M'),\n",
       " Timestamp('2020-10-31 00:00:00', freq='M'),\n",
       " Timestamp('2020-11-30 00:00:00', freq='M'),\n",
       " Timestamp('2020-12-31 00:00:00', freq='M'),\n",
       " Timestamp('2021-01-31 00:00:00', freq='M'),\n",
       " Timestamp('2021-02-28 00:00:00', freq='M'),\n",
       " Timestamp('2021-03-31 00:00:00', freq='M'),\n",
       " Timestamp('2021-04-30 00:00:00', freq='M'),\n",
       " Timestamp('2021-05-31 00:00:00', freq='M'),\n",
       " Timestamp('2021-06-30 00:00:00', freq='M'),\n",
       " Timestamp('2021-07-31 00:00:00', freq='M'),\n",
       " Timestamp('2021-08-31 00:00:00', freq='M'),\n",
       " Timestamp('2021-09-30 00:00:00', freq='M'),\n",
       " Timestamp('2021-10-31 00:00:00', freq='M')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "\n",
    "today = date.today()\n",
    "last_year_date = today - relativedelta(months=12)\n",
    "starting_date ='2016-01-01'\n",
    "\n",
    "ending_date = today - relativedelta(months=12)\n",
    "end_of_month = date(today.year, today.month, 1) + relativedelta(months=1, days=-1)\n",
    "\n",
    "print(end_of_month)\n",
    "\n",
    "[date for date in pd.date_range(start=starting_date, end=end_of_month, freq='1M')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2016-01-31 00:00:00', freq='M'),\n",
       " Timestamp('2016-02-29 00:00:00', freq='M'),\n",
       " Timestamp('2016-03-31 00:00:00', freq='M'),\n",
       " Timestamp('2016-04-30 00:00:00', freq='M'),\n",
       " Timestamp('2016-05-31 00:00:00', freq='M'),\n",
       " Timestamp('2016-06-30 00:00:00', freq='M'),\n",
       " Timestamp('2016-07-31 00:00:00', freq='M'),\n",
       " Timestamp('2016-08-31 00:00:00', freq='M'),\n",
       " Timestamp('2016-09-30 00:00:00', freq='M'),\n",
       " Timestamp('2016-10-31 00:00:00', freq='M'),\n",
       " Timestamp('2016-11-30 00:00:00', freq='M'),\n",
       " Timestamp('2016-12-31 00:00:00', freq='M'),\n",
       " Timestamp('2017-01-31 00:00:00', freq='M'),\n",
       " Timestamp('2017-02-28 00:00:00', freq='M'),\n",
       " Timestamp('2017-03-31 00:00:00', freq='M'),\n",
       " Timestamp('2017-04-30 00:00:00', freq='M'),\n",
       " Timestamp('2017-05-31 00:00:00', freq='M'),\n",
       " Timestamp('2017-06-30 00:00:00', freq='M'),\n",
       " Timestamp('2017-07-31 00:00:00', freq='M'),\n",
       " Timestamp('2017-08-31 00:00:00', freq='M'),\n",
       " Timestamp('2017-09-30 00:00:00', freq='M'),\n",
       " Timestamp('2017-10-31 00:00:00', freq='M'),\n",
       " Timestamp('2017-11-30 00:00:00', freq='M'),\n",
       " Timestamp('2017-12-31 00:00:00', freq='M'),\n",
       " Timestamp('2018-01-31 00:00:00', freq='M'),\n",
       " Timestamp('2018-02-28 00:00:00', freq='M'),\n",
       " Timestamp('2018-03-31 00:00:00', freq='M'),\n",
       " Timestamp('2018-04-30 00:00:00', freq='M'),\n",
       " Timestamp('2018-05-31 00:00:00', freq='M'),\n",
       " Timestamp('2018-06-30 00:00:00', freq='M'),\n",
       " Timestamp('2018-07-31 00:00:00', freq='M'),\n",
       " Timestamp('2018-08-31 00:00:00', freq='M'),\n",
       " Timestamp('2018-09-30 00:00:00', freq='M'),\n",
       " Timestamp('2018-10-31 00:00:00', freq='M'),\n",
       " Timestamp('2018-11-30 00:00:00', freq='M'),\n",
       " Timestamp('2018-12-31 00:00:00', freq='M'),\n",
       " Timestamp('2019-01-31 00:00:00', freq='M'),\n",
       " Timestamp('2019-02-28 00:00:00', freq='M'),\n",
       " Timestamp('2019-03-31 00:00:00', freq='M'),\n",
       " Timestamp('2019-04-30 00:00:00', freq='M'),\n",
       " Timestamp('2019-05-31 00:00:00', freq='M'),\n",
       " Timestamp('2019-06-30 00:00:00', freq='M'),\n",
       " Timestamp('2019-07-31 00:00:00', freq='M'),\n",
       " Timestamp('2019-08-31 00:00:00', freq='M'),\n",
       " Timestamp('2019-09-30 00:00:00', freq='M'),\n",
       " Timestamp('2019-10-31 00:00:00', freq='M'),\n",
       " Timestamp('2019-11-30 00:00:00', freq='M'),\n",
       " Timestamp('2019-12-31 00:00:00', freq='M'),\n",
       " Timestamp('2020-01-31 00:00:00', freq='M'),\n",
       " Timestamp('2020-02-29 00:00:00', freq='M'),\n",
       " Timestamp('2020-03-31 00:00:00', freq='M'),\n",
       " Timestamp('2020-04-30 00:00:00', freq='M'),\n",
       " Timestamp('2020-05-31 00:00:00', freq='M'),\n",
       " Timestamp('2020-06-30 00:00:00', freq='M'),\n",
       " Timestamp('2020-07-31 00:00:00', freq='M'),\n",
       " Timestamp('2020-08-31 00:00:00', freq='M'),\n",
       " Timestamp('2020-09-30 00:00:00', freq='M')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Returns a list with the the time range of equally spaced time points (every 31 days)\n",
    "def date_time(starting_date,ending_date):\n",
    "    date_time_index=pd.date_range(start=starting_date, end=ending_date, freq='1M')\n",
    "    date_range=date_time_index.tolist()\n",
    "    return date_range\n",
    "    # print(type(date_range))\n",
    "    # print ( date_range)\n",
    "    \n",
    "[date for date in pd.date_range(start=starting_date, end=ending_date, freq='1M')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a data frame with vessels data for a speicific period of time\n",
    "\n",
    "def vessel_data(date_range):\n",
    "    vessel_data = []\n",
    "    for n in range(len(date_range)):\n",
    "        end_date=date_range[n].date()\n",
    "        print(end_date)\n",
    "        endpoint = \"https://api.kpler.com/v1/fleet-metrics/vessels\"\n",
    "        payload={}\n",
    "        params_vesseldata = {\"metric\": \"floating_storage\",\n",
    "                         \"zones\":\"world\",\n",
    "                         \"floatingStorageDurationMin\":\"12\", \n",
    "                         \"floatingStorageDurationMax\":\"Inf\", \n",
    "                         \"period\": \"daily\", \n",
    "                         \"products\":\"crude/co\",\n",
    "                         \"unit\":\"kb\",\n",
    "                         \"endDate\":{end_date} }\n",
    "\n",
    "        response_vessel_data = requests.get(endpoint, params=params_vesseldata, headers=headers, data=payload, verify=False)\n",
    "        response_vessel_data_content = response_vessel_data.content\n",
    "        vessel_data_df = pd.read_csv(io.StringIO(response_vessel_data_content.decode('utf-8')), sep=';', parse_dates=[1], infer_datetime_format=True)\n",
    "        vessel_data.append(vessel_data_df)\n",
    "    vessel_data = pd.concat(vessel_data)\n",
    "    vessel_data['IMO']=vessel_data['IMO'].astype(str).astype(int64)\n",
    "    return vessel_data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.kpler.com/v1/fleet-metrics/vessels?metric=floating_storage&zones=world&floatingStorageDurationMin=12&floatingStorageDurationMax=Inf&period=daily&products=crude/co&unit=kb&endDate=2021-10-13'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "end_date = date.today()\n",
    "params_vesseldata = {\"metric\": \"floating_storage\",\n",
    "                         \"zones\":\"world\",\n",
    "                         \"floatingStorageDurationMin\":\"12\", \n",
    "                         \"floatingStorageDurationMax\":\"Inf\", \n",
    "                         \"period\": \"daily\", \n",
    "                         \"products\":\"crude/co\",\n",
    "                         \"unit\":\"kb\",\n",
    "                         \"endDate\": end_date.strftime('%Y-%m-%d')}\n",
    "\n",
    "endpoint = \"https://api.kpler.com/v1/fleet-metrics/vessels\"\n",
    "\n",
    "def get_params(param_list):\n",
    "    return '&'.join([f\"{k}={v}\" for k, v in param_list.items()])\n",
    "\n",
    "\n",
    "f\"{endpoint}?{get_params(params_vesseldata)}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vessel_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert IMO column from object to int64\n",
    "##vessel_data.IMO.astype(int64)\n",
    "#vessel_data['IMO']=vessel_data['IMO'].astype(str).astype(int64)\n",
    "#vessel_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get vessel details  from '/v1/vessels'\n",
    "\n",
    "The Vessels query returns a list of the snapshot of the current status of the fleet, including details on vessel status, IMO, vessel type\n",
    "\n",
    "parameters\n",
    "- \"columns\": \"vessel_status,vessel_type,vessel_imo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a data frame with vessels details, names & types\n",
    "def vessel():\n",
    "    endpoint = \"https://api.kpler.com/v1/vessels\"\n",
    "    payload={}\n",
    "    headers = {\"Authorization\": \"Basic ZGlvbnlzaWEubHluZ29wb3Vsb3VAaWVhLm9yZzpHbHJ6dDB6bg==\"}\n",
    "    params_vesseldetails = {\"columns\": \"vessel_status,vessel_type,vessel_imo\"}\n",
    "\n",
    "    response_vessel = requests.get(endpoint, params=params_vesseldetails, headers=headers, data=payload, verify=False)\n",
    "    response_vessel_content = response_vessel.content\n",
    "    vessel_df = pd.read_csv(io.StringIO(response_vessel_content.decode('utf-8')), sep=';')\n",
    "    return vessel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response_vessel.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response_vessel_content = response_vessel.content\n",
    "#vessel_df = pd.read_csv(io.StringIO(response_vessel_content.decode('utf-8')), sep=';')\n",
    "#vessel_df.to_csv(r'C:\\Users\\LYNGOPOULOU_D\\PycharmProjects\\scraper\\filestore\\output_response_vessel_details.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vessel_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = pd.merge(vessel_data, vessel_df, how=\"left\", on=\"IMO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result.to_csv(r'C:\\Users\\LYNGOPOULOU_D\\PycharmProjects\\scraper\\filestore\\output_reult.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Historical data (2016- lastyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "last_year_date = today - relativedelta(months=12)\n",
    "starting_date ='2016-01-01'\n",
    "ending_date = today - relativedelta(months=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-01-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-02-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-03-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-04-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-06-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-08-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-09-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-10-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-11-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-02-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-04-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-06-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "date_range_his=date_time(starting_date,ending_date)\n",
    "vessel_data_hist=vessel_data(date_range_his)\n",
    "vessel_data_hist.to_csv(r'C:\\Users\\LYNGOPOULOU_D\\PycharmProjects\\scraper\\filestore\\output_response_vessel_hist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vessel_df= vessel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_hist = pd.merge(vessel_data_hist, vessel_df, how=\"left\", on=\"IMO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_hist.to_csv(r'C:\\Users\\LYNGOPOULOU_D\\PycharmProjects\\scraper\\filestore\\floating_storage_hist.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Current data ( lastyear - today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ending_date = date.today()\n",
    "starting_date = today - relativedelta(months=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "date_range=date_time(starting_date,ending_date)\n",
    "vessel_data=vessel_data(date_range)\n",
    "vessel_data.to_csv(r'C:\\Users\\LYNGOPOULOU_D\\PycharmProjects\\scraper\\filestore\\output_response_vessel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYNGOPOULOU_D\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:979: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.kpler.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vessel_df= vessel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(vessel_data, vessel_df, how=\"left\", on=\"IMO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(r'C:\\Users\\LYNGOPOULOU_D\\PycharmProjects\\scraper\\filestore\\floating_storage.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ROSA_L\\PycharmProjects\\scraper\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:scraper.core.factory:Loading module scraper.jobs.com_kpler.floating_storage\n",
      "DEBUG:scraper.core.factory:Getting class FloatingStorageJob\n",
      "INFO:scraper.core.job:Temporary table name: #floating_storage_temp, final table name: floating_storage_data\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:Getting sources...\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:70 sources to load.\n",
      "INFO:scraper.core.utils:download_and_get_checksum: 36.02027893066406 ms\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2021-10-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-10-31 HTTP/1.1\" 200 846\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2021-09-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-09-30 HTTP/1.1\" 200 869\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2021-08-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-08-31 HTTP/1.1\" 200 869\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2021-07-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-07-31 HTTP/1.1\" 200 869\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2021-06-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-06-30 HTTP/1.1\" 200 869\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2021-05-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-05-31 HTTP/1.1\" 200 869\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2021-04-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-04-30 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2021-03-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-03-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2021-02-28\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-02-28 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2021-01-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-01-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2020-12-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-12-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2020-11-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-11-30 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2020-10-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-10-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2020-09-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-09-30 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2020-08-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-08-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2020-07-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-07-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2020-06-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-06-30 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2020-05-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-05-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2020-04-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-04-30 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2020-03-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-03-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2020-02-29\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-02-29 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2020-01-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-01-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2019-12-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-12-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2019-11-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-11-30 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2019-10-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-10-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2019-09-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-09-30 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2019-08-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-08-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2019-07-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-07-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2019-06-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-06-30 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2019-05-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-05-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2019-04-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-04-30 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2019-03-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-03-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2019-02-28\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-02-28 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2019-01-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-01-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2018-12-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-12-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2018-11-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-11-30 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2018-10-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-10-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2018-09-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-09-30 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2018-08-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-08-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2018-07-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-07-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2018-06-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-06-30 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2018-05-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-05-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2018-04-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-04-30 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2018-03-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-03-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2018-02-28\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-02-28 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2018-01-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-01-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2017-12-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-12-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2017-11-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-11-30 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2017-10-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-10-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2017-09-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-09-30 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2017-08-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-08-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2017-07-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-07-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2017-06-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-06-30 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2017-05-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-05-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2017-04-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-04-30 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2017-03-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-03-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2017-02-28\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-02-28 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2017-01-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-01-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2016-12-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-12-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2016-11-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-11-30 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2016-10-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-10-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2016-09-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-09-30 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2016-08-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-08-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2016-07-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-07-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2016-06-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-06-30 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2016-05-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-05-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2016-04-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-04-30 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2016-03-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-03-31 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2016-02-29\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-02-29 HTTP/1.1\" 200 823\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2016-01-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-01-31 HTTP/1.1\" 200 823\n",
      "INFO:scraper.core.utils:rm_sources_up_to_date: 2802.668809890747 ms\n",
      "DEBUG:scraper.core.job:Adding sources to dynamic_dim['source']...\n",
      "DEBUG:scraper.core.job:70 sources added to self.dynamic_dim['source']\n",
      "DEBUG:scraper.core.job:remove_existing_dynamic_dim: query - http://vipenta.iea.org:8000/dimension/source\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source HTTP/1.1\" 200 835907\n",
      "DEBUG:scraper.core.job:self.dynamic_dim['source'] size before: 70\n",
      "DEBUG:scraper.core.job:self.dynamic_dim['source'] size after: 0\n",
      "DEBUG:scraper.core.job:Transforming provider ...\n",
      "DEBUG:scraper.core.job:Adding provider to dynamic_dim: COM_KPLER\n",
      "DEBUG:scraper.core.job:remove_existing_dynamic_dim: query - http://vipenta.iea.org:8000/dimension/provider\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/provider HTTP/1.1\" 200 8530\n",
      "DEBUG:scraper.core.job:self.dynamic_dim['provider'] size before: 1\n",
      "DEBUG:scraper.core.job:self.dynamic_dim['provider'] size after: 0\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:Transforming data\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:1571 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2016-01-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:1930 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2016-02-29.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2329 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2016-03-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2479 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2016-04-30.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2975 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2016-05-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2912 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2016-06-30.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2628 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2016-07-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2276 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2016-08-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2173 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2016-09-30.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2454 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2016-10-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2659 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2016-11-30.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2843 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2016-12-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2879 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2017-01-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2778 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2017-02-28.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2705 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2017-03-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2362 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2017-04-30.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2596 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2017-05-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2912 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2017-06-30.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2750 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2017-07-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2607 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2017-08-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2319 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2017-09-30.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:1973 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2017-10-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:1788 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2017-11-30.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:1706 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2017-12-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:1705 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2018-01-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:1654 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2018-02-28.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:1478 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2018-03-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:1150 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2018-04-30.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:1461 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2018-05-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:1983 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2018-06-30.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:1506 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2018-07-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:1563 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2018-08-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:1385 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2018-09-30.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:1257 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2018-10-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:1390 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2018-11-30.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:1868 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2018-12-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:1850 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2019-01-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:1704 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2019-02-28.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:1932 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2019-03-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2166 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2019-04-30.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2243 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2019-05-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2772 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2019-06-30.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2991 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2019-07-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2693 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2019-08-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2526 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2019-09-30.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2552 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2019-10-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2668 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2019-11-30.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2288 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2019-12-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2496 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2020-01-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2378 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2020-02-29.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:2591 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2020-03-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:3650 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2020-04-30.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:5813 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2020-05-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:5974 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2020-06-30.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:5845 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2020-07-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:5446 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2020-08-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:5119 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2020-09-30.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:4286 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2020-10-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:4082 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2020-11-30.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:4049 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2020-12-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:3175 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2021-01-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:3091 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2021-02-28.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:3377 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2021-03-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:3258 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2021-04-30.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:3266 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2021-05-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:3041 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2021-06-30.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:3388 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2021-07-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:3319 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2021-08-31.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:3315 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2021-09-30.csv\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:1606 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2021-10-31.csv\n",
      "DEBUG:scraper.core.job:Running insert_new_dynamic_dim(): 2 items\n",
      "DEBUG:scraper.core.job:Processing source: size 0\n",
      "DEBUG:scraper.core.job:Processing provider: size 0\n",
      "INFO:scraper.core.utils:insert_new_dynamic_dim: 1.9993782043457031 ms\n",
      "INFO:scraper.core.job:Writing to database.\n",
      "DEBUG:scraper.core.job:Database: mssql+pyodbc://omr:Sekiyu8trd@vipenta.iea.org/external_db_dev?driver=ODBC+Driver+13+for+SQL+Server\n",
      "DEBUG:scraper.core.job:Sending truncate table statement\n",
      "INFO:scraper.core.job:Creating schema kpler\n",
      "ERROR:scraper.core.job:Schema kpler already exists. Ignoring it.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\rosa_l\\pycharmprojects\\scraper\\venv\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1248, in _execute_context\n",
      "    cursor, statement, parameters, context\n",
      "  File \"c:\\users\\rosa_l\\pycharmprojects\\scraper\\venv\\lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 590, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "pyodbc.ProgrammingError: ('42S01', \"[42S01] [Microsoft][ODBC Driver 13 for SQL Server][SQL Server]There is already an object named 'kpler' in the database. (2714) (SQLExecDirectW); [42S01] [Microsoft][ODBC Driver 13 for SQL Server][SQL Server]CREATE SCHEMA failed due to previous errors. (2759)\")\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 1075, in upsert\n",
      "    engine.execute(f\"CREATE SCHEMA {self.db_schema}\")\n",
      "  File \"c:\\users\\rosa_l\\pycharmprojects\\scraper\\venv\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 2191, in execute\n",
      "    return connection.execute(statement, *multiparams, **params)\n",
      "  File \"c:\\users\\rosa_l\\pycharmprojects\\scraper\\venv\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 976, in execute\n",
      "    return self._execute_text(object_, multiparams, params)\n",
      "  File \"c:\\users\\rosa_l\\pycharmprojects\\scraper\\venv\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1151, in _execute_text\n",
      "    parameters,\n",
      "  File \"c:\\users\\rosa_l\\pycharmprojects\\scraper\\venv\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1288, in _execute_context\n",
      "    e, statement, parameters, cursor, context\n",
      "  File \"c:\\users\\rosa_l\\pycharmprojects\\scraper\\venv\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1482, in _handle_dbapi_exception\n",
      "    sqlalchemy_exception, with_traceback=exc_info[2], from_=e\n",
      "  File \"c:\\users\\rosa_l\\pycharmprojects\\scraper\\venv\\lib\\site-packages\\sqlalchemy\\util\\compat.py\", line 178, in raise_\n",
      "    raise exception\n",
      "  File \"c:\\users\\rosa_l\\pycharmprojects\\scraper\\venv\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1248, in _execute_context\n",
      "    cursor, statement, parameters, context\n",
      "  File \"c:\\users\\rosa_l\\pycharmprojects\\scraper\\venv\\lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 590, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "sqlalchemy.exc.ProgrammingError: (pyodbc.ProgrammingError) ('42S01', \"[42S01] [Microsoft][ODBC Driver 13 for SQL Server][SQL Server]There is already an object named 'kpler' in the database. (2714) (SQLExecDirectW); [42S01] [Microsoft][ODBC Driver 13 for SQL Server][SQL Server]CREATE SCHEMA failed due to previous errors. (2759)\")\n",
      "[SQL: CREATE SCHEMA kpler]\n",
      "(Background on this error at: http://sqlalche.me/e/f405)\n",
      "INFO:scraper.core.job:Loading 187954 rows to database.\n",
      "DEBUG:scraper.core.job:Creating table floating_storage_data with these columns: Index(['Date', 'IMO', 'Name', 'Dead Weight Tonnage', 'Quantity (kb)', 'Family',\n",
      "       'Group', 'Product', 'Grade', 'Current Continent',\n",
      "       'Current Subcontinent', 'Current Country', 'Current Sea',\n",
      "       'Number of Floating Days', 'Floating Since', 'provider', 'source',\n",
      "       'date_created', 'date_modified'],\n",
      "      dtype='object')\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-01-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7094 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-02-29 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7095 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-03-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7096 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-04-30 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7097 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-05-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7098 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-06-30 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7099 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-07-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7100 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-08-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7101 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-09-30 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7102 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-10-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7103 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-11-30 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7104 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2016-12-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7105 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-01-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7106 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-02-28 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7107 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-03-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7108 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-04-30 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7109 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-05-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7110 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-06-30 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7111 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-07-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7112 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-08-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7113 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-09-30 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7114 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-10-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7115 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-11-30 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7116 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2017-12-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7117 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-01-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7118 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-02-28 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7119 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-03-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7120 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-04-30 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7121 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-05-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7122 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-06-30 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7123 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-07-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7124 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-08-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7125 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-09-30 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7126 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-10-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7127 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-11-30 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7128 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2018-12-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7129 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-01-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7130 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-02-28 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7131 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-03-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7132 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-04-30 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7133 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-05-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7134 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-06-30 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7135 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-07-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7136 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-08-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7137 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-09-30 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7138 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-10-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7139 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-11-30 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7140 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2019-12-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7141 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-01-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7142 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-02-29 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7143 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-03-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7144 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-04-30 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7145 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-05-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7146 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-06-30 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7147 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-07-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7148 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-08-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7149 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-09-30 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7150 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-10-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7151 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-11-30 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7152 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2020-12-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7153 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-01-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7154 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-02-28 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7155 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-03-31 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7156 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-04-30 HTTP/1.1\" 200 823\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7157 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-05-31 HTTP/1.1\" 200 869\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7088 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-06-30 HTTP/1.1\" 200 869\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7089 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-07-31 HTTP/1.1\" 200 869\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7090 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-08-31 HTTP/1.1\" 200 869\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7091 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-09-30 HTTP/1.1\" 200 869\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7092 HTTP/1.1\" 201 10\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-10-31 HTTP/1.1\" 200 846\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7093 HTTP/1.1\" 201 10\n",
      "INFO:scraper.core.utils:update_sources_metadata: 5104.722499847412 ms\n"
     ]
    }
   ],
   "source": [
    "from scraper.core import factory\n",
    "\n",
    "job = factory.get_scraper_job('com_kpler', 'floating_storage', full_load=True)\n",
    "job.run(download=False)\n",
    "# job.get_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:scraper.core.factory:Loading module scraper.jobs.com_kpler.floating_storage\n",
      "DEBUG:scraper.core.factory:Getting class FloatingStorageJob\n",
      "INFO:scraper.core.job:Temporary table name: #floating_storage_temp, final table name: floating_storage_data\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:Getting sources...\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:6 sources to load.\n",
      "INFO:scraper.core.utils:download_and_get_checksum: 4.000663757324219 ms\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2021-10-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-10-31 HTTP/1.1\" 200 869\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2021-09-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-09-30 HTTP/1.1\" 200 869\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: removing com_kpler_fs_data_2021-09-30 from self.sources\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2021-08-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-08-31 HTTP/1.1\" 200 869\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: removing com_kpler_fs_data_2021-08-31 from self.sources\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2021-07-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-07-31 HTTP/1.1\" 200 869\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: removing com_kpler_fs_data_2021-07-31 from self.sources\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2021-06-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-06-30 HTTP/1.1\" 200 869\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: removing com_kpler_fs_data_2021-06-30 from self.sources\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_data_2021-05-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-05-31 HTTP/1.1\" 200 869\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: removing com_kpler_fs_data_2021-05-31 from self.sources\n",
      "INFO:scraper.core.utils:rm_sources_up_to_date: 189.985990524292 ms\n",
      "DEBUG:scraper.core.job:Adding sources to dynamic_dim['source']...\n",
      "DEBUG:scraper.core.job:1 sources added to self.dynamic_dim['source']\n",
      "DEBUG:scraper.core.job:remove_existing_dynamic_dim: query - http://vipenta.iea.org:8000/dimension/source\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source HTTP/1.1\" 200 837402\n",
      "DEBUG:scraper.core.job:self.dynamic_dim['source'] size before: 1\n",
      "DEBUG:scraper.core.job:self.dynamic_dim['source'] size after: 0\n",
      "DEBUG:scraper.core.job:Transforming provider ...\n",
      "DEBUG:scraper.core.job:Adding provider to dynamic_dim: COM_KPLER\n",
      "DEBUG:scraper.core.job:remove_existing_dynamic_dim: query - http://vipenta.iea.org:8000/dimension/provider\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/provider HTTP/1.1\" 200 8530\n",
      "DEBUG:scraper.core.job:self.dynamic_dim['provider'] size before: 1\n",
      "DEBUG:scraper.core.job:self.dynamic_dim['provider'] size after: 0\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:Transforming data\n",
      "INFO:scraper.jobs.com_kpler.floating_storage:1606 rows read from C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\filestore\\com_kpler_fs_data_2021-10-31.csv\n",
      "DEBUG:scraper.core.job:Running insert_new_dynamic_dim(): 2 items\n",
      "DEBUG:scraper.core.job:Processing source: size 0\n",
      "DEBUG:scraper.core.job:Processing provider: size 0\n",
      "INFO:scraper.core.utils:insert_new_dynamic_dim: 2.0008087158203125 ms\n",
      "INFO:scraper.core.job:Writing to database.\n",
      "DEBUG:scraper.core.job:Database: mssql+pyodbc://omr:Sekiyu8trd@vipenta.iea.org/external_db_dev?driver=ODBC+Driver+13+for+SQL+Server\n",
      "DEBUG:scraper.core.job:Loading 1606 rows to temporary table #floating_storage_temp\n",
      "DEBUG:scraper.core.job:Merging data from #floating_storage_temp into floating_storage_data\n",
      "DEBUG:scraper.core.job:Merge query: MERGE kpler.floating_storage_data target \n",
      "USING kpler.#floating_storage_temp as source \n",
      "ON (target.[provider] = source.[provider] AND target.[source] = source.[source] AND target.[Date] = source.[Date] AND target.[IMO] = source.[IMO] AND target.[Product] = source.[Product] AND target.[Grade] = source.[Grade]) \n",
      "WHEN MATCHED AND (target.[Name] <> source.[Name] OR target.[Dead Weight Tonnage] <> source.[Dead Weight Tonnage] OR target.[Quantity (kb)] <> source.[Quantity (kb)] OR target.[Family] <> source.[Family] OR target.[Group] <> source.[Group] OR target.[Current Continent] <> source.[Current Continent] OR target.[Current Subcontinent] <> source.[Current Subcontinent] OR target.[Current Country] <> source.[Current Country] OR target.[Current Sea] <> source.[Current Sea] OR target.[Number of Floating Days] <> source.[Number of Floating Days] OR target.[Floating Since] <> source.[Floating Since])\n",
      "THEN UPDATE SET target.[Name] = source.[Name], target.[Dead Weight Tonnage] = source.[Dead Weight Tonnage], target.[Quantity (kb)] = source.[Quantity (kb)], target.[Family] = source.[Family], target.[Group] = source.[Group], target.[Current Continent] = source.[Current Continent], target.[Current Subcontinent] = source.[Current Subcontinent], target.[Current Country] = source.[Current Country], target.[Current Sea] = source.[Current Sea], target.[Number of Floating Days] = source.[Number of Floating Days], target.[Floating Since] = source.[Floating Since], target.[date_modified] = GETDATE()\n",
      "WHEN NOT MATCHED \n",
      "THEN INSERT ([Date], [IMO], [Name], [Dead Weight Tonnage], [Quantity (kb)], [Family], [Group], [Product], [Grade], [Current Continent], [Current Subcontinent], [Current Country], [Current Sea], [Number of Floating Days], [Floating Since], [provider], [source], [date_created]) \n",
      "VALUES (source.[Date], source.[IMO], source.[Name], source.[Dead Weight Tonnage], source.[Quantity (kb)], source.[Family], source.[Group], source.[Product], source.[Grade], source.[Current Continent], source.[Current Subcontinent], source.[Current Country], source.[Current Sea], source.[Number of Floating Days], source.[Floating Since], source.[provider], source.[source], GETDATE());\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_data_2021-10-31 HTTP/1.1\" 200 869\n",
      "ERROR:scraper.core.job:Exception in update_sources_metadata(): 'BaseSource' object has no attribute 'last_download'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ROSA_L\\PycharmProjects\\scraper\\scraper\\core\\job.py\", line 881, in update_sources_metadata\n",
      "    data[\"last_download\"] = source.last_download\n",
      "AttributeError: 'BaseSource' object has no attribute 'last_download'\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7093 HTTP/1.1\" 201 10\n",
      "INFO:scraper.core.utils:update_sources_metadata: 74.01108741760254 ms\n"
     ]
    }
   ],
   "source": [
    "from scraper.core import factory\n",
    "\n",
    "job = factory.get_scraper_job('com_kpler', 'floating_storage')\n",
    "job.run(download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 187954 entries, 0 to 1605\n",
      "Data columns (total 19 columns):\n",
      " #   Column                   Non-Null Count   Dtype         \n",
      "---  ------                   --------------   -----         \n",
      " 0   Date                     187954 non-null  object        \n",
      " 1   IMO                      187954 non-null  int64         \n",
      " 2   Name                     187954 non-null  object        \n",
      " 3   Dead Weight Tonnage      187954 non-null  int64         \n",
      " 4   Quantity (kb)            187954 non-null  int64         \n",
      " 5   Family                   187954 non-null  object        \n",
      " 6   Group                    187954 non-null  object        \n",
      " 7   Product                  159257 non-null  object        \n",
      " 8   Grade                    154376 non-null  object        \n",
      " 9   Current Continent        185235 non-null  object        \n",
      " 10  Current Subcontinent     185214 non-null  object        \n",
      " 11  Current Country          185298 non-null  object        \n",
      " 12  Current Sea              186442 non-null  object        \n",
      " 13  Number of Floating Days  187954 non-null  int64         \n",
      " 14  Floating Since           187954 non-null  object        \n",
      " 15  provider                 187954 non-null  object        \n",
      " 16  source                   187954 non-null  object        \n",
      " 17  date_created             187954 non-null  datetime64[ns]\n",
      " 18  date_modified            0 non-null       datetime64[ns]\n",
      "dtypes: datetime64[ns](2), int64(4), object(13)\n",
      "memory usage: 28.7+ MB\n"
     ]
    }
   ],
   "source": [
    "job.data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2015-12-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-05-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-12-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-12-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-10-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-12-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-07-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-12-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-11-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-02-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2014-11-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2014-09-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-08-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-12-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-05-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-06-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-12-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-10-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-10-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-05-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-03-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-07-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-10-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-09-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-10-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-12-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-11-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-04-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-12-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-07-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-01-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-12-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-10-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-11-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-12-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-12-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-12-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-12-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-10-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-12-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-12-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-09-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-12-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-12-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-12-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-12-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-12-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-12-31 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-03-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-09-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-08-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-05-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-10-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-08-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-12-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-09-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-01-31 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-03-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-10-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-09-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-10-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-09-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-09-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-03-31 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-04-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-10-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-04-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-07-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-02-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-31 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-07-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-05-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-06-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-05-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-10-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-05-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-07-31 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-10-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2014-09-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-31 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-08-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2014-09-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-09-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-10-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-02-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-03-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-02-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-10-31 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-10-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-11-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-31 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2016-12-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-04-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-01-31 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-02-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2015-07-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-03-31 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-04-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-31 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-06-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-31 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-05-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-07-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-08-31 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-09-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-31 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-10-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-11-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2017-12-31 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-01-31 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-02-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-31 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-03-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-04-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-05-31 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-22 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-27 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-28 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-29 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-30 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-01 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-02 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-03 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-04 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-05 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-06 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-07 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-08 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-09 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-10 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-11 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-12 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-13 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-14 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-15 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-06-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-16 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-17 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-18 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-19 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-20 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-21 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-24 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-25 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-26 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2018-07-27 00:00:00+0000', tz='UTC'),\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.data['Floating Since'].drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'code': 'com_kpler_fs_data_2021-05-31',\n",
       "  'url': 'http://api-oil.kpler.com/v1/fleet-metrics/vessels?metric=floating_storage&zones=world&floatingStorageDurationMin=12&floatingStorageDurationMax=Inf&period=daily&products=crude/co&unit=kb&endDate=2021-05-31',\n",
       "  'path': 'com_kpler_fs_data_2021-05-31.csv',\n",
       "  'long_name': 'KPLER - vessel data for 2021-05-31'},\n",
       " {'code': 'com_kpler_fs_data_2021-06-30',\n",
       "  'url': 'http://api-oil.kpler.com/v1/fleet-metrics/vessels?metric=floating_storage&zones=world&floatingStorageDurationMin=12&floatingStorageDurationMax=Inf&period=daily&products=crude/co&unit=kb&endDate=2021-06-30',\n",
       "  'path': 'com_kpler_fs_data_2021-06-30.csv',\n",
       "  'long_name': 'KPLER - vessel data for 2021-06-30'},\n",
       " {'code': 'com_kpler_fs_data_2021-07-31',\n",
       "  'url': 'http://api-oil.kpler.com/v1/fleet-metrics/vessels?metric=floating_storage&zones=world&floatingStorageDurationMin=12&floatingStorageDurationMax=Inf&period=daily&products=crude/co&unit=kb&endDate=2021-07-31',\n",
       "  'path': 'com_kpler_fs_data_2021-07-31.csv',\n",
       "  'long_name': 'KPLER - vessel data for 2021-07-31'},\n",
       " {'code': 'com_kpler_fs_data_2021-08-31',\n",
       "  'url': 'http://api-oil.kpler.com/v1/fleet-metrics/vessels?metric=floating_storage&zones=world&floatingStorageDurationMin=12&floatingStorageDurationMax=Inf&period=daily&products=crude/co&unit=kb&endDate=2021-08-31',\n",
       "  'path': 'com_kpler_fs_data_2021-08-31.csv',\n",
       "  'long_name': 'KPLER - vessel data for 2021-08-31'},\n",
       " {'code': 'com_kpler_fs_data_2021-09-30',\n",
       "  'url': 'http://api-oil.kpler.com/v1/fleet-metrics/vessels?metric=floating_storage&zones=world&floatingStorageDurationMin=12&floatingStorageDurationMax=Inf&period=daily&products=crude/co&unit=kb&endDate=2021-09-30',\n",
       "  'path': 'com_kpler_fs_data_2021-09-30.csv',\n",
       "  'long_name': 'KPLER - vessel data for 2021-09-30'},\n",
       " {'code': 'com_kpler_fs_data_2021-10-31',\n",
       "  'url': 'http://api-oil.kpler.com/v1/fleet-metrics/vessels?metric=floating_storage&zones=world&floatingStorageDurationMin=12&floatingStorageDurationMax=Inf&period=daily&products=crude/co&unit=kb&endDate=2021-10-31',\n",
       "  'path': 'com_kpler_fs_data_2021-10-31.csv',\n",
       "  'long_name': 'KPLER - vessel data for 2021-10-31'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vars(s) for s in job.sources]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:scraper.core.job:download: True, parallel download: False\n",
      "DEBUG:scraper.jobs.com_kpler.floating_storage:Downloading com_kpler_fs_data_2021-05-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): proxy.iea.org:8080\n",
      "DEBUG:urllib3.connectionpool:http://proxy.iea.org:8080 \"GET http://api-oil.kpler.com/v1/fleet-metrics/vessels?metric=floating_storage&zones=world&floatingStorageDurationMin=12&floatingStorageDurationMax=Inf&period=daily&products=crude/co&unit=kb&endDate=2021-05-31 HTTP/1.1\" 301 134\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-oil.kpler.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api-oil.kpler.com:443 \"GET /v1/fleet-metrics/vessels?metric=floating_storage&zones=world&floatingStorageDurationMin=12&floatingStorageDurationMax=Inf&period=daily&products=crude/co&unit=kb&endDate=2021-05-31 HTTP/1.1\" 200 None\n",
      "DEBUG:scraper.jobs.com_kpler.floating_storage:Downloading com_kpler_fs_data_2021-06-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): proxy.iea.org:8080\n",
      "DEBUG:urllib3.connectionpool:http://proxy.iea.org:8080 \"GET http://api-oil.kpler.com/v1/fleet-metrics/vessels?metric=floating_storage&zones=world&floatingStorageDurationMin=12&floatingStorageDurationMax=Inf&period=daily&products=crude/co&unit=kb&endDate=2021-06-30 HTTP/1.1\" 301 134\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-oil.kpler.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api-oil.kpler.com:443 \"GET /v1/fleet-metrics/vessels?metric=floating_storage&zones=world&floatingStorageDurationMin=12&floatingStorageDurationMax=Inf&period=daily&products=crude/co&unit=kb&endDate=2021-06-30 HTTP/1.1\" 200 None\n",
      "DEBUG:scraper.jobs.com_kpler.floating_storage:Downloading com_kpler_fs_data_2021-07-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): proxy.iea.org:8080\n",
      "DEBUG:urllib3.connectionpool:http://proxy.iea.org:8080 \"GET http://api-oil.kpler.com/v1/fleet-metrics/vessels?metric=floating_storage&zones=world&floatingStorageDurationMin=12&floatingStorageDurationMax=Inf&period=daily&products=crude/co&unit=kb&endDate=2021-07-31 HTTP/1.1\" 301 134\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-oil.kpler.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api-oil.kpler.com:443 \"GET /v1/fleet-metrics/vessels?metric=floating_storage&zones=world&floatingStorageDurationMin=12&floatingStorageDurationMax=Inf&period=daily&products=crude/co&unit=kb&endDate=2021-07-31 HTTP/1.1\" 200 None\n",
      "DEBUG:scraper.jobs.com_kpler.floating_storage:Downloading com_kpler_fs_data_2021-08-31\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): proxy.iea.org:8080\n",
      "DEBUG:urllib3.connectionpool:http://proxy.iea.org:8080 \"GET http://api-oil.kpler.com/v1/fleet-metrics/vessels?metric=floating_storage&zones=world&floatingStorageDurationMin=12&floatingStorageDurationMax=Inf&period=daily&products=crude/co&unit=kb&endDate=2021-08-31 HTTP/1.1\" 301 134\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-oil.kpler.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api-oil.kpler.com:443 \"GET /v1/fleet-metrics/vessels?metric=floating_storage&zones=world&floatingStorageDurationMin=12&floatingStorageDurationMax=Inf&period=daily&products=crude/co&unit=kb&endDate=2021-08-31 HTTP/1.1\" 200 None\n",
      "DEBUG:scraper.jobs.com_kpler.floating_storage:Downloading com_kpler_fs_data_2021-09-30\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): proxy.iea.org:8080\n",
      "DEBUG:urllib3.connectionpool:http://proxy.iea.org:8080 \"GET http://api-oil.kpler.com/v1/fleet-metrics/vessels?metric=floating_storage&zones=world&floatingStorageDurationMin=12&floatingStorageDurationMax=Inf&period=daily&products=crude/co&unit=kb&endDate=2021-09-30 HTTP/1.1\" 301 134\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-oil.kpler.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api-oil.kpler.com:443 \"GET /v1/fleet-metrics/vessels?metric=floating_storage&zones=world&floatingStorageDurationMin=12&floatingStorageDurationMax=Inf&period=daily&products=crude/co&unit=kb&endDate=2021-09-30 HTTP/1.1\" 200 None\n",
      "DEBUG:scraper.jobs.com_kpler.floating_storage:Downloading COM_KPLER_fs_detail\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): proxy.iea.org:8080\n",
      "DEBUG:urllib3.connectionpool:http://proxy.iea.org:8080 \"GET http://api-oil.kpler.com/v1/vessels?columns=vessel_status,vessel_type,vessel_imo HTTP/1.1\" 301 134\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-oil.kpler.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api-oil.kpler.com:443 \"GET /v1/vessels?columns=vessel_status,vessel_type,vessel_imo HTTP/1.1\" 200 None\n",
      "INFO:scraper.core.utils:download_and_get_checksum: 43646.70991897583 ms\n"
     ]
    }
   ],
   "source": [
    "job.download_and_get_checksum(download=True, parallel_download=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test vessel detail job\n",
    "\n",
    "We've just separated this into a separate scraper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:scraper.core.factory:Loading module scraper.jobs.com_kpler.vessel_details\n",
      "DEBUG:scraper.core.factory:Getting class VesselDetailsJob\n",
      "INFO:scraper.core.job:Temporary table name: #vessel_temp, final table name: vessel_data\n",
      "INFO:scraper.jobs.com_kpler.vessel_details:Getting sources...\n",
      "INFO:scraper.jobs.com_kpler.vessel_details:1 sources to load.\n",
      "DEBUG:scraper.core.job:download: True, parallel download: True\n",
      "DEBUG:scraper.jobs.com_kpler.vessel_details:Downloading com_kpler_fs_detail\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): proxy.iea.org:8080\n",
      "DEBUG:urllib3.connectionpool:http://proxy.iea.org:8080 \"GET http://api-oil.kpler.com/v1/vessels?columns=vessel_status,vessel_type,vessel_imo HTTP/1.1\" 301 134\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api-oil.kpler.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api-oil.kpler.com:443 \"GET /v1/vessels?columns=vessel_status,vessel_type,vessel_imo HTTP/1.1\" 200 None\n",
      "INFO:scraper.core.utils:download_and_get_checksum: 17048.01654815674 ms\n",
      "DEBUG:scraper.core.job:rm_sources_up_to_date: processing com_kpler_fs_detail\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_detail HTTP/1.1\" 200 692\n",
      "INFO:scraper.core.utils:rm_sources_up_to_date: 69.49019432067871 ms\n",
      "DEBUG:scraper.core.job:Adding sources to dynamic_dim['source']...\n",
      "DEBUG:scraper.core.job:1 sources added to self.dynamic_dim['source']\n",
      "DEBUG:scraper.core.job:remove_existing_dynamic_dim: query - http://vipenta.iea.org:8000/dimension/source\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source HTTP/1.1\" 200 778091\n",
      "DEBUG:scraper.core.job:self.dynamic_dim['source'] size before: 1\n",
      "DEBUG:scraper.core.job:self.dynamic_dim['source'] size after: 0\n",
      "DEBUG:scraper.core.job:Transforming provider ...\n",
      "DEBUG:scraper.core.job:Adding provider to dynamic_dim: COM_KPLER\n",
      "DEBUG:scraper.core.job:remove_existing_dynamic_dim: query - http://vipenta.iea.org:8000/dimension/provider\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/provider HTTP/1.1\" 200 8530\n",
      "DEBUG:scraper.core.job:self.dynamic_dim['provider'] size before: 1\n",
      "DEBUG:scraper.core.job:self.dynamic_dim['provider'] size after: 0\n",
      "INFO:scraper.jobs.com_kpler.vessel_details:Transforming data\n",
      "INFO:scraper.jobs.com_kpler.vessel_details:10442 rows processed.\n",
      "DEBUG:scraper.core.job:Running insert_new_dynamic_dim(): 2 items\n",
      "DEBUG:scraper.core.job:Processing source: size 0\n",
      "DEBUG:scraper.core.job:Processing provider: size 0\n",
      "INFO:scraper.core.utils:insert_new_dynamic_dim: 1.981496810913086 ms\n",
      "INFO:scraper.core.job:Writing to database.\n",
      "DEBUG:scraper.core.job:Database: mssql+pyodbc://omr:Sekiyu8trd@vipenta.iea.org/external_db_dev?driver=ODBC+Driver+13+for+SQL+Server\n",
      "DEBUG:scraper.core.job:Sending truncate table statement\n",
      "INFO:scraper.core.job:Creating schema kpler\n",
      "INFO:scraper.core.job:Loading 10442 rows to database.\n",
      "DEBUG:scraper.core.job:Creating table vessel_data with these columns: Index(['Status', 'Vessel type', 'IMO', 'provider', 'source', 'date_created',\n",
      "       'date_modified'],\n",
      "      dtype='object')\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"GET /dimension/source?code=com_kpler_fs_detail HTTP/1.1\" 200 692\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): vipenta.iea.org:8000\n",
      "DEBUG:urllib3.connectionpool:http://vipenta.iea.org:8000 \"PUT /dimension/source/7087 HTTP/1.1\" 201 10\n",
      "INFO:scraper.core.utils:update_sources_metadata: 110.21113395690918 ms\n"
     ]
    }
   ],
   "source": [
    "from scraper.core import factory\n",
    "\n",
    "job = factory.get_scraper_job('com_kpler', 'vessel_details', full_load=True)\n",
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2016, 1, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "# '2016-01-01'\n",
    "date(2016, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
